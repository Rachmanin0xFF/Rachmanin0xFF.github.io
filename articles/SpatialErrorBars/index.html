<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=format-detection content="telephone=no"><meta name=HandheldFriendly content=true><meta name=MobileOptimized content=320><meta name=viewport content="initial-scale=1,width=device-width"><title>Adam Lastowka - Make Your Averages Better-Than-Average</title><meta name=description content=""><script async defer src=./../../scripts/parallax.js onload="var loaded=true;"></script><link rel=stylesheet id=lightmodehl href=./../../scripts/highlight/styles/atom-one-light.min.css><link rel=stylesheet id=darkmodehl href=./../../scripts/highlight/styles/hybrid.min.css disabled><script src=./../../scripts/highlight/highlight.min.js></script><script>hljs.highlightAll();</script><link rel=stylesheet href=./../../post.css><script defer src=./../../scripts/darkmode.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script type=text/x-mathjax-config>MathJax = {
    tex: {
      inlineMath: [['$', '$'], ["\\(", "\\)"]],
      processEscapes: true,
    }
  }</script><link rel=icon href=./../../favicon.ico type=image/x-icon><link rel="shortcut icon" href=./../../favicon.ico type=image/x-icon></head><body><div id=bkg><section id=not-background><section id=sidebar><div class=sticky><div class="sb-big onbkg hvr-rotate"><a href=../../index.html>Home</a></div><br><div class="sb-big onbkg hvr-rotate"><a href=../../about/index.html>About</a></div><br><div class="sb-big onbkg hvr-rotate"><a href=../../qa/index.html>Q&A</a></div><!--<br><br><div id="dm-toggle" class="button sb-big hvr-rotate">Lights</button>--></div></section><section id=header><div class=null><div id=spikes class=vector alt=""></div></div><div id=sitename><h5><a href=./../../index.html>Adam<br>Lastowka</a></h5></div></section><div id=foreground><section id=feed><h1>Make Your Averages Better-Than-Average</h1><div class=date>Published: Apr 15, 2025</div><div class=tags>Tagged with: <a href=./../../topics/math/index.html>math</a> <a href=./../../topics/stats/index.html>stats</a> <a href=./../../topics/cs/index.html>cs</a> <a href=./../../topics/gis/index.html>gis</a></div><br><p>Take a look at these two points:</p><div class=imblock><img src=twopoints.png class=postim></div><p>Think of these points as <strong>repeated measurements of the same thing</strong> — whether it&#39;s the coordinates of an ice cream shop in two different datasets, the orientation of a <a href=https://en.wikipedia.org/wiki/Astrophysical_jet>relativistic jet</a> as inferred from two different telescopes, or my IQ and likability score from two different online quizzes.</p><p>Quick: how would you <strong>combine</strong> these two measurements? The red dataset says the ice cream shop is at (0, 0), and the blue one says it&#39;s at (2, 2). We often default to a few options:</p><ol><li>Average the two points</li><li>Use the more &#39;accurate&#39; point and discard the other</li><li>Apply some sort of ad-hoc weighted average</li></ol><p>These methods aren&#39;t bad! Number 2 is often a good choice. But for this data, the &#39;best&#39; merge location is actually right here, in green:</p><div class=imblock><img src=twopoints_merge.png class=postim></div>Confused? Let's unpack this.<h2 id=background-error-bars>Background: Error Bars</h2><p>Data is meaningless without some guarantee of precision. In most real-world datasets, this guarantee is implicit; hiding in the dataset&#39;s implied use case, the <a href=https://xkcd.com/2170/ >number of decimal digits</a>, or maybe just a vague collection of industry-specific assumptions. Error bars are awesome because they let you <strong>make that guarantee explicit</strong>. An error bar is just a tag that says &quot;hey, here&#39;s how closely I represent the thing I&#39;m measuring&quot;. Having that information can save time, effort, and make matching / merging data much easier.</p><p>Unfortunately, the real-world situation is as follows (YMMV depending on your industry):</p><ul><li><strong>Most</strong> datasets: No mention of error whatsoever.</li><li><strong>Some</strong> datasets: A global statement about some sort of ill-defined &#39;accuracy&#39;, &#39;resolution&#39;, or &#39;precision&#39;, or maybe per-measurement error bars, but no explanation as to what they mean. Statements like &quot;accurate to within 10 meters&quot; fall in here.</li><li><strong>Unicorns / (good) scientists</strong>: Per-measurement error bars with a description of what the error means, covariances, and an explanation of how the error was determined/propagated. This category includes statements like: &quot;random error in position is approximately Gaussian with a 95% confidence interval of ±10 meters in all directions&quot;.</li></ul><p>Part of the problem is that tracking and manipulating error isn&#39;t always a straightforward task. Modern databases aren&#39;t exactly streamlined for error propagation, and modifying your pipelines to handle error doesn&#39;t always pitch well.</p><p>Still, if you&#39;re willing to take the plunge (or at least hear about it), keep reading.</p><h2 id=merging-measurements-1-d>Merging Measurements (1-D)</h2><p>I&#39;ll use a <a href=https://x.com/adamlastowka/status/1698148223603368314>real-world</a> example: I just took my temperature with two thermometers. One reads 99.1°F, the other 97.7°F. The website for the first one says it&#39;s accurate to within ±0.9°F (it&#39;s a food thermometer), and the second says it&#39;s accurate to ±0.3°F. They&#39;re unlabeled, but these ranges are <em>probably</em> 95% confidence intervals, which are equivalent to <a href="https://www.wolframalpha.com/input?i=InverseCDF%5BNormalDistribution%5B0%2C1%5D%2C0.975%5D">about 2 standard deviations</a>. So, in sum, the situation is:</p><ul><li>Thermometer A: Measured 99.1°F with a standard deviation of 0.45°F</li><li>Thermometer B: Measured 97.7°F with a standard deviation of 0.15°F</li></ul><p>If we plot two Gaussians (bell curves, a <a href=https://en.wikipedia.org/wiki/Central_limit_theorem>very reasonable assumption</a> for our measurement error) with these properties, the graph looks like <a href=https://www.desmos.com/calculator/zp2xhlhka3>this</a>:</p><div class=imblock><img src=twogauss.png class=postim></div><p>Visually, the way to combine these measurements seems pretty obvious: look at where they overlap (this also lets you <em>validate</em> measurements, as we&#39;ll see later)! Formally, since these are probability densities of independent measurements, we can just <em>multiply them together</em>. After normalization, that gives us this curve, which is also a Gaussian (the product of two Gaussians is also a Gaussian):</p><div class=imblock><img src=twogauss_merge.png class=postim></div><p>Which has a mean of 97.8°F and a standard deviation of 0.14°F. I&#39;ll write the formulae for the new mean (\(\mu\)) and standard deviation (\(\sigma\)) below (I won&#39;t bore you with the derivation):</p><p>\[ \begin{align} \mu_\textrm{combined}&amp;=\frac{{\sigma_1}^2\mu_2 + {\sigma_2}^2\mu_1}{{\sigma_1}^2+{\sigma_2}^2} \\ \sigma_\textrm{combined} &amp;= \sqrt\frac{1}{1/{\sigma_1}^{2}+1/{\sigma_2}^{2}} \end{align} \]</p><p>If you prefer code:</p><pre><code class=language-python>def combine_measurements_1D(meas_1, stdev_1, meas_2, stdev_2):
    combined_meas = ((stdev_1**2)*meas_2 + (stdev_2**2)*meas_1)/(stdev_1**2 + stdev_2**2)
    combined_stdev = (stdev_1**-2 + stdev_2**-2)**-0.5
    return combined_meas, combined_stdev
</code></pre><p>A few things about this strategy:</p><ul><li><strong>It&#39;s the &quot;right way&quot; to merge observations</strong>. This is plain-old statistics; there is no better way to combine independent measurements. This operation is the bread-and-butter of scientific reports.</li><li><strong>It&#39;s not that complicated</strong>. The Greek letters above might seem intimidating to non-mathematicians, but the whole process boils down to just two one-line variable assignments.</li><li><strong>It&#39;s just a weighted average.</strong> Specifically, it&#39;s weighted by the variances (standard deviation squared) of our measurements.</li><li><strong>Combining measurements increased our accuracy.</strong> In this case, the effect was minor, but merging measurements will always shrink error bars, never widen them. If you merge two datasets that both say &quot;±10 meters&quot;, your combined data will have an error of ±7 meters.</li></ul><h2 id=merging-measurements-2-d>Merging Measurements (2-D)</h2><p>Let&#39;s return to the two points from earlier:</p><div class=imblock><img src=twopoints.png class=postim></div>The key bit of information I left out earlier (apologies) is that these points *also* have error bars:<div class=imblock><img src=twomultivar.png class=postim></div><p>The ellipses around each point represent confidence intervals (20%, 40%, 60%, 80%, 95%, and 99%). Interestingly, the point in the upper right has an <em>asymmetry</em> in its error: its y-coordinate is much more accurate than its x-coordinate. I can think of a few cases where this might happen (specifically in geospatial data, since that&#39;s what I&#39;ve been up to lately):</p><ol><li>Oblique aerial imagery — flat features will appear &#39;squished&#39; along one axis, so any error bars will do the same.</li><li>Linearly referenced features — you might know a pothole is <em>on</em> a road (±5 meters), but not precisely where along that road (±30 meters).</li><li>Lat/lon near the poles: in Norway, &quot;5 decimal places of precision&quot; means two times the accuracy in longitude than in latitude.</li></ol><p>Actually, we got an easy case here: the direction of greatest/least uncertainty often <em>isn&#39;t even aligned</em> with the axes; we could&#39;ve ended up with something like this:</p><div class=imblock><img src=twomultivar_angle.png class=postim></div><p>The &#39;full treatment&#39; of this sort of error requires knowing not just the standard deviation in x and y, but also whether those uncertainties are correlated. Mathematically, we can accomplish this with a <strong>covariance matrix</strong>. This sounds scary, but it&#39;s just a list of four numbers that describe how your uncertainty is smeared out in space. Here are some examples:</p><div class=imblock><img src=covariance_matrices.png class=postim></div>If you're someone who likes to learn by playing, check out [this](https://www.infinitecuriosity.org/vizgp/) somewhat-tangential-but-still-really-cool interactive demo.<p>Again, to properly merge two measurements in 2D, we just multiply their distributions together:</p><div class=imblock><img src=twomultivar_merge.png class=postim></div><p>The math to recover the resulting (still Gaussian) blob is a little bit trickier; we&#39;ll need to know both the means \(\mu_1, \mu_2\) and the covariance matrices of both points \( \Sigma_1, \Sigma_2 \) (capital \(\Sigma\) instead of lowercase \(\sigma\)): \[ \begin{align} \mu_\textrm{combined} &amp;= \Sigma_2(\Sigma_1 + \Sigma_2)^{-1}\mu_1 + \Sigma_1(\Sigma_1 + \Sigma_2)^{-1}\mu_2\\ \Sigma_\textrm{combined}&amp;=\Sigma_1(\Sigma_1 + \Sigma_2)^{-1}\Sigma_2 \end{align} \] Keep in mind that the \(\Sigma\) are matrices, the \(\mu\) are vectors, the products are matrix multiplications, and the inverses are matrix inverses. The equivalent Python (using numpy) is:</p><pre><code class=language-python>import numpy as np
def combine_measurements(meas_1, cov_1, meas_2, cov_2):
    reusable_inverse = np.linalg.inv(cov_1 + cov_2)
    combined_cov = cov_1 @ reusable_inverse @ cov_2
    combined_meas = cov_2 @ reusable_inverse @ meas_1 + cov_1 @ reusable_inverse @ meas_2
    return combined_meas, combined_cov
</code></pre><p>Because the 2x2 matrix inverse has a <a href=https://www.mathcentre.ac.uk/resources/uploaded/sigma-matrices7-2009-1.pdf>not-terribly-large closed-form expression</a>, you <em>could</em> write this all out in something without using any sort of linear algebra libraries.</p><p>By the way, here&#39;s a function to generate a covariance matrix for lat/lon coordinates (<a href=https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset#Common_EPSG_codes>EPSG4326</a>) with precision specified in meters:</p><pre><code class=language-python># Note: this only works for uncertainties much less than Earth radius
# (because the world appears 'flat' up close)
def get_cov(lat, lon, error_meters):
    # use the mean WGS84 radius
    # (it's okay if error bars are off by less than 1%)
    meters_to_deg = 57.2958 / 6.371e6
    error_deg = meters_to_deg * error_meters
    mercator_stretch = np.cos(lat / 57.2958)
    return np.array([[error_deg, 0.0], [0.0, error_deg * mercator_stretch]])
</code></pre><h2 id=the-middle-ground>The Middle Ground</h2><p>If you&#39;re an engineer reading this, you&#39;re probably thinking &quot;yeah, no way I&#39;m attaching a covariance matrix to every coordinate in my data&quot;. Honestly — same. That level of detail is beyond the point of diminishing returns, and most spatial error is roughly symmetric, anyway.</p><p>For easier consumption, I&#39;ll provide some concise, practical functions to <strong>combine and validate</strong> data from two different sources, <strong>assuming both sources have Gaussian error bars that look the same in every direction</strong> (isotropy).</p><h3 id=merging-two-features>Merging Two Features</h3><p>This is simple; we just apply the 1-D procedure to each coordinate. With Numpy&#39;s operator overloading, our code doesn&#39;t even change:</p><pre><code class=language-python>def combine_measurements(meas_1: np.array, err_1: float, meas_2: np.array, err_2: float) -> np.array:
    '''
    Returns a combined measurement formed from two independent measurements of the same feature, each with isotropic Gaussian error.
    Parameters:
        - meas_1: The first measurement, in any units
        - err_1: The (Gaussian) error in the first measurement (could be standard deviation, 95% confidence, or anything else)
        - meas_2: The second measurement, in the same units
        - err_2: The error in the second measurements (interpretation must match err_1)
    '''
    combined_meas = ((err_2**2)*meas_1 + (err_1**2)*meas_2)/(err_1**2 + err_2**2)
    combined_err = (err_1**-2 + err_2**-2)**-0.5
    return combined_meas, combined_err
</code></pre><h3 id=validating-a-match-chi-squared-test>Validating a Match (Chi-Squared Test)</h3><p>One of the most powerful features of error bars is that they let you confidently <em>reject</em> matches. If my thermometers had said (95±0.3)°F and (100±0.1)°F, I could state with extreme confidence (a one in \(2.6\times10^{56}\) chance of being incorrect) that either they were measuring different temperatures, or someone got their error bars <em>very</em> wrong. If you have standard deviations available, here are some functions for calculating frequentist match probabilities:</p><pre><code class=language-python>def get_agreement_2D(meas_1: np.array, stdev_1: float, meas_2: np.array, stdev_2: float):
    '''
    Returns a value [0, 1] indicating how well two data points 'agree' with each other.
    Specifically, returns the probability of observing a difference between measurments greater than this one, given the input error bars.
    Parameters:
        meas_1: The first measurement (a 2D vector).
        meas_2: The second measurement (a 2D vector).
        stdev_1: The symmetric standard deviation of the first measurement.
        stdev_2: The symmetric standard deviation of the second measurement.
    '''
    meas_diff = meas_2 - meas_1
    inv_variance_sum = 1.0 / (stdev_1**2 + stdev_2**2)
    D_squared = np.sum((meas_diff**2) * inv_variance_sum)
    # Chi-squared CDF with 2DOF
    p = 1.0 - np.exp(-D_squared/2.0)
    return 1.0 - p
</code></pre><p>If you <em>do</em> have covariances, here&#39;s the more general form:</p><pre><code class=language-python>import numpy as np
from scipy.stats import chi2
def get_agreement_ND(meas_1, cov_1, meas_2, cov_2):
    meas_diff = meas_2 - meas_1
    cov_sum = cov_1 + cov_2
    inv_cov_sum = np.linalg.inv(cov_sum)
    D_squared = meas_diff.T @ inv_cov_sum @ meas_diff
    k = len(meas_1)
    p = 1.0 - chi2.cdf(D_squared, df=k)
    return 1.0 - p
</code></pre><p>Lastly, here&#39;s a 1-liner for the 1-D version:</p><pre><code class=language-python>from math import erf
def get_agreement_1D(meas_1, stdev_1, meas_2, stdev_2):
    return erf((0.5 * (meas_2 - meas_1)**2 / (stdev_1**2 + stdev_2**2))**0.5)
</code></pre><p>When interpreting the results from these functions, remember that an &#39;agreement&#39; of 0.1 doesn&#39;t mean <em>no</em> agreement: you should expect true matches to have an &#39;agreement&#39; less than or equal to 0.1 precisely 10% of the time.</p><p>One last thing worth noting — <a href=https://astronomy.stackexchange.com/questions/47539/how-do-you-propagate-asymmetric-errors-on-the-practical-way-to>error is not always Gaussian</a>. The real world is not always so simple, and the formulae I&#39;ve provided here may fail in those cases. Still, this is better than nothing. Good luck!</p><h2 id=further-reading>Further Reading:</h2><ul><li><a href=https://books.tarbaweya.org/static/documents/uploads/pdf/An%20introduction%20to%20error%20analysis%20.pdf>&quot;Introduction to Error Analysis&quot; by John R. Taylor</a> is an excellent practical handbook.</li><li><a href=https://pubs.usgs.gov/tm/11c3/ >REPTool</a> is an ArcGIS toolkit for propagating errors through raster data.</li><li>Here&#39;s an <a href=https://geostatisticslessons.com/lessons/errorellipses>awesome blog post</a> talking about combining multivariate Gaussians.</li><li>The multivariate Gaussian ellipse plots in this post were made with <a href=https://gist.github.com/Rachmanin0xFF/ba57d7b7be58335f30b54027ba2fd6c9>this Python script</a>.</li></ul><a href=./../../articles\Embedding\index.html class=button2 style=min-width:47%;>Next Post:<br>Embedding the Shortest-Path Metric</a></section><div id=footer></div></div></section></div></body></html>